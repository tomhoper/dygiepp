2020-05-31 22:20:53,663 - INFO - allennlp.common.params - random_seed = 13370
2020-05-31 22:20:53,663 - INFO - allennlp.common.params - numpy_seed = 1337
2020-05-31 22:20:53,663 - INFO - allennlp.common.params - pytorch_seed = 133
2020-05-31 22:20:54,138 - INFO - allennlp.common.checks - Pytorch version: 1.2.0
2020-05-31 22:20:54,142 - INFO - allennlp.common.params - evaluate_on_test = False
2020-05-31 22:20:54,142 - INFO - allennlp.common.params - validation_dataset_reader = None
2020-05-31 22:20:54,142 - INFO - allennlp.common.params - dataset_reader.lazy = None
2020-05-31 22:20:54,149 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'context_width': 1, 'debug': False, 'max_span_width': 8, 'token_indexers': {'bert': {'do_lowercase': False, 'pretrained_model': 'pretrained/scibert_scivocab_cased/vocab.txt', 'type': 'bert-pretrained', 'use_starting_offsets': True}}, 'type': 'ie_json'} and extras set()
2020-05-31 22:20:54,149 - INFO - allennlp.common.params - dataset_reader.type = ie_json
2020-05-31 22:20:54,149 - INFO - allennlp.common.from_params - instantiating class <class 'dygie.data.dataset_readers.ie_json.IEJsonReader'> from params {'context_width': 1, 'debug': False, 'max_span_width': 8, 'token_indexers': {'bert': {'do_lowercase': False, 'pretrained_model': 'pretrained/scibert_scivocab_cased/vocab.txt', 'type': 'bert-pretrained', 'use_starting_offsets': True}}} and extras set()
2020-05-31 22:20:54,149 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8
2020-05-31 22:20:54,150 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'pretrained/scibert_scivocab_cased/vocab.txt', 'type': 'bert-pretrained', 'use_starting_offsets': True} and extras set()
2020-05-31 22:20:54,150 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = bert-pretrained
2020-05-31 22:20:54,150 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'pretrained/scibert_scivocab_cased/vocab.txt', 'use_starting_offsets': True} and extras set()
2020-05-31 22:20:54,150 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = pretrained/scibert_scivocab_cased/vocab.txt
2020-05-31 22:20:54,150 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = True
2020-05-31 22:20:54,150 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = False
2020-05-31 22:20:54,150 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2020-05-31 22:20:54,150 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2020-05-31 22:20:54,150 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.truncate_long_sequences = True
2020-05-31 22:20:54,151 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file pretrained/scibert_scivocab_cased/vocab.txt
2020-05-31 22:20:54,246 - INFO - allennlp.common.params - dataset_reader.context_width = 1
2020-05-31 22:20:54,246 - INFO - allennlp.common.params - dataset_reader.debug = False
2020-05-31 22:20:54,246 - INFO - allennlp.common.params - dataset_reader.lazy = False
2020-05-31 22:20:54,246 - INFO - allennlp.common.params - dataset_reader.predict_hack = False
2020-05-31 22:20:54,247 - INFO - allennlp.common.params - train_data_path = train.json
2020-05-31 22:20:54,247 - INFO - allennlp.training.util - Reading training data from train.json
