{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "expected an indented block (eval_utils.py, line 71)",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/net/nfs2.corp/s2-research/tomh/miniconda3/envs/nfsenv/allennlp/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-1c7e2e7c8e9b>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from eval_utils import ie_eval\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/net/nfs2.corp/s2-research/tomh/dygiepp/eval_utils.py\"\u001b[0;36m, line \u001b[0;32m71\u001b[0m\n\u001b[0;31m    return match\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os   \n",
    "import shutil\n",
    "import subprocess\n",
    "from typing import Any, Dict\n",
    "import sys\n",
    "import pandas as pd\n",
    "from eval_utils import ie_eval\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from eval_utils import relation_matching\n",
    "import spacy \n",
    "\n",
    "root_path = Path(\"../coviddata\")\n",
    "anno_dir = root_path / \"Annotations\"\n",
    "annotator_files = list(anno_dir.glob('*.tsv'))\n",
    "print(annotator_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "golddf = pd.read_csv(annotator_files[1], sep=\"\\t\",header=None, names=[\"id\",\"text\",\"arg0\",\"arg1\",\"rel\",\"y\"])\n",
    "golddf = golddf[golddf[\"y\"]==\"accept\"]\n",
    "golddf[\"rel\"][golddf[\"rel\"]==\"DO\"] =\"MECHANISM\"\n",
    "golddf[\"rel\"][golddf[\"rel\"].str.contains(\"USED\")] = \"MECHANISM\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens0gold = golddf[\"arg0\"].str.split().str.len()\n",
    "lens1gold = golddf[\"arg1\"].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "7.0"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "lens1gold.quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "../coviddata/Annotations/arezou_annotations.tsv\n16.19999999999999\n28.799999999999983\n../coviddata/Annotations/jeff_annotations.tsv\n9.849999999999994\n14.0\n../coviddata/Annotations/kristina_annotations.tsv\n17.19999999999999\n25.0\n../coviddata/Annotations/megan_annotations.tsv\n19.0\n21.0\n"
    }
   ],
   "source": [
    "for annofile in [a for a in annotator_files if \"mad\" not in a.name]:\n",
    "    print(annofile)\n",
    "    #map USED/DO to MECH\n",
    "    annodf = pd.read_csv(annofile, sep=\"\\t\",header=None, names=[\"id\",\"text\",\"arg0\",\"arg1\",\"rel\",\"y\"])\n",
    "    lens0anno= annodf[\"arg0\"].str.split().str.len()\n",
    "    lens1anno = annodf[\"arg1\"].str.split().str.len()\n",
    "    lens0gold.quantile(0.9)\n",
    "    print(lens0anno.quantile(0.95))\n",
    "    print(lens1anno.quantile(0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[PosixPath('../coviddata/Annotations/arezou_annotations.tsv'),\n PosixPath('../coviddata/Annotations/madeline_annotations.tsv'),\n PosixPath('../coviddata/Annotations/jeff_annotations.tsv'),\n PosixPath('../coviddata/Annotations/kristina_annotations.tsv'),\n PosixPath('../coviddata/Annotations/megan_annotations.tsv')]"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "annotator_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match(pair, text, collapse,jaccard_thresh,match_metric,filter_stop,seen_pred_gold,good_preds,span_mode=False):\n",
    "        if collapse:\n",
    "            labels = [1,1]\n",
    "        else:\n",
    "            labels = [pair[0][2],pair[1][2]]\n",
    "        m = relation_matching(pair,metric=match_metric, labels = labels,thresh=jaccard_thresh, filter_stop = filter_stop, span_mode= span_mode)\n",
    "        if m and ((i,pair[0][0],pair[0][1],pair[1][0],pair[1][1]) not in seen_pred_gold):\n",
    "            #good_preds.append([i,pair[0],pair[1]])\n",
    "            good_preds.append((i,tuple(pair[0]),tuple(pair[1]),text))\n",
    "            seen_pred_gold[(i,pair[0][0],pair[0][1],pair[1][0],pair[1][1])]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "../coviddata/Annotations/arezou_annotations.tsv\n49\n25\n17\ncollapsed: True metric: substring agree: 0.625\ncollapsed: False metric: substring agree: 0.425\n../coviddata/Annotations/jeff_annotations.tsv\n53\n19\n17\ncollapsed: True metric: substring agree: 0.475\ncollapsed: False metric: substring agree: 0.425\n../coviddata/Annotations/kristina_annotations.tsv\n24\n21\n19\ncollapsed: True metric: substring agree: 0.525\ncollapsed: False metric: substring agree: 0.475\n../coviddata/Annotations/megan_annotations.tsv\n47\n28\n23\ncollapsed: True metric: substring agree: 0.7\ncollapsed: False metric: substring agree: 0.575\n"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "../coviddata/Annotations/arezou_annotations.tsv\n68\n36\n27\ncollapsed: True metric: substring agree: 0.631578947368421\ncollapsed: False metric: substring agree: 0.47368421052631576\n../coviddata/Annotations/jeff_annotations.tsv\n77\n30\n28\ncollapsed: True metric: substring agree: 0.5263157894736842\ncollapsed: False metric: substring agree: 0.49122807017543857\n../coviddata/Annotations/kristina_annotations.tsv\n36\n31\n29\ncollapsed: True metric: substring agree: 0.543859649122807\ncollapsed: False metric: substring agree: 0.5087719298245614\n../coviddata/Annotations/megan_annotations.tsv\n66\n39\n34\ncollapsed: True metric: substring agree: 0.6842105263157895\ncollapsed: False metric: substring agree: 0.5964912280701754\n"
    }
   ],
   "source": [
    "\n",
    "jaccard_thresh = 0.3\n",
    "#iterate over annotator files except gold\n",
    "for annofile in [a for a in annotator_files if \"mad\" not in a.name]:\n",
    "    print(annofile)\n",
    "    #map USED/DO to MECH\n",
    "    annodf = pd.read_csv(annofile, sep=\"\\t\",header=None, names=[\"id\",\"text\",\"arg0\",\"arg1\",\"rel\",\"y\"])\n",
    "    annodf = annodf[annodf[\"y\"]==\"accept\"]\n",
    "    lens0anno= annodf[\"arg0\"].str.split().str.len()\n",
    "    lens1anno = annodf[\"arg1\"].str.split().str.len()\n",
    "    \n",
    "    annodf[\"rel\"][annodf[\"rel\"]==\"DO\"] =\"MECHANISM\"\n",
    "    annodf[\"rel\"][annodf[\"rel\"].str.contains(\"USED\")] = \"MECHANISM\"\n",
    "    overlap = set(annodf.id).intersection(set(golddf.id))\n",
    "    #use only overalpping documents\n",
    "    annodf = annodf[annodf[\"id\"].isin(overlap)]\n",
    "    golddf = golddf[golddf[\"id\"].isin(overlap)]\n",
    "\n",
    "    goldrels = golddf[[\"id\",\"arg0\",\"arg1\",\"rel\"]]#.drop_duplicates()\n",
    "    goldrels = goldrels.drop_duplicates(subset =[\"id\",\"arg0\",\"arg1\"]).set_index(\"id\")\n",
    "    if \"conf\" in annodf.columns:\n",
    "        predrels = annodf[[\"id\",\"arg0\",\"arg1\",\"rel\",\"conf\"]].drop_duplicates(subset =[\"id\",\"arg0\",\"arg1\"]).set_index(\"id\",inplace=False)\n",
    "    else:\n",
    "        predrels = annodf[[\"id\",\"arg0\",\"arg1\",\"rel\"]].drop_duplicates(subset =[\"id\",\"arg0\",\"arg1\"]).set_index(\"id\",inplace=False)\n",
    "    \n",
    "    print(len(predrels))\n",
    "    good_preds1 = []\n",
    "    seen_pred_gold1 = {}\n",
    "    good_preds2 = []\n",
    "    seen_pred_gold2 = {}\n",
    "\n",
    "    match_count = 0\n",
    "    for i in predrels.index.unique():\n",
    "        if i in goldrels.index.unique():\n",
    "            gold = goldrels.loc[i]\n",
    "            text = golddf[golddf.id == i][\"text\"].unique()\n",
    "            if type(predrels.loc[i]) == pd.core.series.Series:\n",
    "                preds = [predrels.loc[i].values]\n",
    "            else:\n",
    "                preds = predrels.loc[i].values\n",
    "            c = list(itertools.product(gold.values, preds))\n",
    "            #for each pair, find gold-annotation matches according to different criteria (e.g., collapse true/false or match_metric jaccard/substring)\n",
    "            #compute agreement \n",
    "            #find the diff between two criteria for each annotator and save to disk\n",
    "            for pair in c:\n",
    "                collapse = True\n",
    "                get_match(pair,text = text,collapse=collapse,jaccard_thresh=jaccard_thresh,match_metric='substring',filter_stop=True,seen_pred_gold = seen_pred_gold1,\\\n",
    "                good_preds=good_preds1)\n",
    "                collapse = False\n",
    "                get_match(pair, text =text,collapse=collapse,jaccard_thresh= jaccard_thresh,match_metric=\"substring\",filter_stop=True,seen_pred_gold = seen_pred_gold2,\\\n",
    "                good_preds = good_preds2)\n",
    "    print(len(good_preds1))\n",
    "    print(len(good_preds2))\n",
    "\n",
    "    print('collapsed: {0} metric: {1} agree: {2}'.format(True, 'substring',len(good_preds1)/len(goldrels)))          \n",
    "    print('collapsed: {0} metric: {1} agree: {2}'.format(False, 'substring',len(good_preds2)/len(goldrels)))\n",
    "\n",
    "    diff_csv = []\n",
    "    for g in good_preds1:\n",
    "        if tuple(g) not in good_preds2:\n",
    "            diff_csv.append([g[0],g[3],g[1][0],g[1][1],g[1][2],g[2][0],g[2][1],g[2][2]])\n",
    "    \n",
    "    pd.DataFrame(diff_csv,columns = [\"abstract_id\",\"text\",\"gold_arg0\",\"gold_arg1\",\"gold_label\",\"anno_arg0\",\"anno_arg1\",\"anno_label\"]).to_csv(annofile.name+\"_diff_gold.csv\",header=True,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array(['PROBE', 'commercial eXplosives Identification Tool', 'MECHANISM'],\n       dtype=object),\n array(['( XIT )',\n        'transform disparate , often paper - based , information on commercial explosives and articles into a standardized electronic database',\n        'MECHANISM'], dtype=object))"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hypothesis = \"Alanine substitution\"\n",
    "\n",
    "reference = \"Alanine substitution of either Arg-76 or Tyr-94 in the N - terminal domain of IBV N protein\"\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(reference, hypothesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = rouge.get_scores(\"r\", \"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[{'rouge-1': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n  'rouge-l': {'f': 0.0, 'p': 0.0, 'r': 0.0}}]"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(pair[0][1])\n",
    "[t for t in doc if t.dep_ ==\"ROOT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "commercial eXplosives Identification Tool"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[Tool]"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "[t for t in doc if t.dep_ ==\"ROOT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['( XIT )',\n       'transform disparate , often paper - based , information on commercial explosives and articles into a standardized electronic database',\n       'MECHANISM'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitallennlpconda12d55c2195cb49daa24f83d300014659",
   "display_name": "Python 3.7.7 64-bit ('allennlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}